#%%
"""
Navigation World Model Analysis Script
å¯¼èˆªä¸–ç•Œæ¨¡å‹åˆ†æè„šæœ¬ - æµ‹è¯•go_stanfordæ•°æ®é›†ä¸Šè®­ç»ƒçš„æ¨¡å‹æ•ˆæœ

ä½¿ç”¨Jupyter cellé£æ ¼ (#%%)ï¼Œå¯åœ¨VS Codeä¸­é€æ­¥è¿è¡Œ
"""

import sys
import os
import numpy as np
import matplotlib.pyplot as plt
import torch
import random
import pickle
import h5py
import cv2
from pathlib import Path
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.abspath('.'))

# å¯¼å…¥V-JEPAç›¸å…³æ¨¡å—
from app.vjepa_droid.transforms import make_transforms
from notebooks.utils.world_model_wrapper import WorldModel
from notebooks.utils.mpc_utils import compute_new_pose, poses_to_diff

# è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¤ç°æ€§
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
torch.manual_seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

print("âœ… å¯¼å…¥å®Œæˆï¼Œéšæœºç§å­å·²è®¾ç½®")

#%%
"""
Cell 1: åŠ è½½è®­ç»ƒå¥½çš„å¯¼èˆªæ¨¡å‹
"""

# æ¨¡å‹è·¯å¾„å’Œå‚æ•°
# checkpoint_path = "/nvmessd/yinzi/vjepa2/checkpoints/go_stanford_finetune_8gpu_0818_12_18/e20.pt"
checkpoint_path = "/nvmessd/yinzi/vjepa2/checkpoints/go_stanford_finetune_8gpu/latest.pt"
crop_size = 256
device = "cuda" if torch.cuda.is_available() else "cpu"

print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡: {device}")
print(f"ğŸ“‚ åŠ è½½checkpoint: {checkpoint_path}")

# æ£€æŸ¥checkpointæ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists(checkpoint_path):
    print(f"âŒ Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
    print("è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®")
else:
    print("âœ… Checkpointæ–‡ä»¶å­˜åœ¨")

# åŠ è½½é¢„è®­ç»ƒçš„V-JEPA2-ACæ¨¡å‹ä½œä¸ºåŸºç¡€
print("ğŸ“¥ åŠ è½½åŸºç¡€V-JEPA2-ACæ¨¡å‹...")
encoder, predictor = torch.hub.load("facebookresearch/vjepa2", "vjepa2_ac_vit_giant")

# åŠ è½½fine-tunedæƒé‡
if os.path.exists(checkpoint_path):
    print("ğŸ“¥ åŠ è½½fine-tunedæƒé‡...")
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    def remove_module_prefix(state_dict):
        """ç§»é™¤state_dictä¸­çš„'module.'å‰ç¼€"""
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith('module.'):
                new_key = key[7:]  # ç§»é™¤'module.'å‰ç¼€
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value
        return new_state_dict
    
    # åŠ è½½encoderæƒé‡
    if 'encoder' in checkpoint:
        encoder_state_dict = remove_module_prefix(checkpoint['encoder'])
        encoder.load_state_dict(encoder_state_dict, strict=False)
        print("âœ… Encoderæƒé‡åŠ è½½æˆåŠŸ")
    
    # åŠ è½½predictoræƒé‡  
    if 'predictor' in checkpoint:
        predictor_state_dict = remove_module_prefix(checkpoint['predictor'])
        predictor.load_state_dict(predictor_state_dict, strict=False)
        print("âœ… Predictoræƒé‡åŠ è½½æˆåŠŸ")
    
    print(f"ğŸ“Š è®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 'unknown')}")
else:
    print("âš ï¸ ä½¿ç”¨é¢„è®­ç»ƒæƒé‡ï¼ˆæœªåŠ è½½fine-tunedï¼‰")

# ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
encoder = encoder.to(device)
predictor = predictor.to(device)
encoder.eval()
predictor.eval()

print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

#%%
"""
Cell 2: åˆå§‹åŒ–æ•°æ®å˜æ¢å’Œæ¨¡å‹å‚æ•°
"""

# è®¡ç®—tokens_per_frame
tokens_per_frame = int((crop_size // encoder.patch_size) ** 2)
print(f"ğŸ¯ Tokens per frame: {tokens_per_frame}")

# åˆå§‹åŒ–æ•°æ®å˜æ¢
transform = make_transforms(
    random_horizontal_flip=False,
    random_resize_aspect_ratio=(1., 1.),
    random_resize_scale=(1., 1.),
    reprob=0.,
    auto_augment=False,
    motion_shift=False,
    crop_size=crop_size,
)

print("âœ… æ•°æ®å˜æ¢åˆå§‹åŒ–å®Œæˆ")

#%%
"""
Cell 3: å¯¼èˆªæ•°æ®é›†è·¯å¾„å’Œé€‰æ‹©æµ‹è¯•æ ·æœ¬
"""

# å¯¼èˆªæ•°æ®é›†è·¯å¾„
csv_path = "/nvmessd/yinzi/vjepa2/go_stanford_converted/go_stanford_train_paths.csv"

print(f"ğŸ“ è¯»å–æ•°æ®é›†ç´¢å¼•: {csv_path}")

# è¯»å–æ‰€æœ‰è½¨è¿¹è·¯å¾„
if not os.path.exists(csv_path):
    print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
    sys.exit(1)

with open(csv_path, 'r') as f:
    episode_paths = [line.strip() for line in f.readlines() if line.strip()]

print(f"ğŸ“Š æ€»å…±æ‰¾åˆ° {len(episode_paths)} ä¸ªå¯¼èˆªè½¨è¿¹")

# æ£€æŸ¥è½¨è¿¹é•¿åº¦åˆ†å¸ƒ
print("ğŸ” æ£€æŸ¥è½¨è¿¹é•¿åº¦åˆ†å¸ƒ...")
trajectory_lengths = []
valid_trajectories = []

for i, ep_path in enumerate(episode_paths[:20]):  # æ£€æŸ¥å‰20ä¸ª
    try:
        ep_clips, ep_states = load_navigation_episode(ep_path)
        length = len(ep_states)
        trajectory_lengths.append(length)
        if length >= 10:  # è‡³å°‘10å¸§çš„è½¨è¿¹
            valid_trajectories.append(ep_path)
        if i < 10:
            print(f"   {os.path.basename(ep_path)}: {length} å¸§")
    except:
        continue

if trajectory_lengths:
    print(f"ğŸ“Š è½¨è¿¹é•¿åº¦ç»Ÿè®¡:")
    print(f"   å¹³å‡é•¿åº¦: {np.mean(trajectory_lengths):.1f} å¸§")
    print(f"   æœ€çŸ­: {np.min(trajectory_lengths)} å¸§")
    print(f"   æœ€é•¿: {np.max(trajectory_lengths)} å¸§")
    print(f"   â‰¥10å¸§çš„è½¨è¿¹æ•°: {len(valid_trajectories)}")
    
    if len(valid_trajectories) > 0:
        print(f"âœ… æ‰¾åˆ° {len(valid_trajectories)} ä¸ªå¯ç”¨è½¨è¿¹")
        # ä½¿ç”¨æ‰¾åˆ°çš„æœ‰æ•ˆè½¨è¿¹
        episode_paths = valid_trajectories
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿé•¿çš„è½¨è¿¹")
else:
    print("âŒ æ— æ³•è¯»å–è½¨è¿¹ä¿¡æ¯")

# éšæœºé€‰æ‹©ä¸€ä¸ªæµ‹è¯•è½¨è¿¹ï¼ˆå›ºå®šç§å­ä¿è¯å¤ç°ï¼‰
test_episode_path = random.choice(episode_paths)
print(f"ğŸ¯ é€‰æ‹©æµ‹è¯•è½¨è¿¹: {os.path.basename(test_episode_path)}")

# æ£€æŸ¥è½¨è¿¹æ–‡ä»¶
video_path = os.path.join(test_episode_path, "recordings/MP4/nav_camera.mp4")
traj_path = os.path.join(test_episode_path, "trajectory.h5")

if not os.path.exists(video_path):
    print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
if not os.path.exists(traj_path):
    print(f"âŒ è½¨è¿¹æ–‡ä»¶ä¸å­˜åœ¨: {traj_path}")

print("âœ… æµ‹è¯•è½¨è¿¹é€‰æ‹©å®Œæˆ")

#%%
"""
Cell 4: åŠ è½½å’Œé¢„å¤„ç†æµ‹è¯•æ•°æ®
"""

def load_navigation_episode(episode_path):
    """åŠ è½½å¯¼èˆªè½¨è¿¹æ•°æ®"""
    video_path = os.path.join(episode_path, "recordings/MP4/nav_camera.mp4")
    traj_path = os.path.join(episode_path, "trajectory.h5")
    
    # åŠ è½½è§†é¢‘
    cap = cv2.VideoCapture(video_path)
    frames = []
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        # è½¬æ¢BGRåˆ°RGB
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frames.append(frame)
    cap.release()
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    frames = np.array(frames)  # [T, H, W, C]
    frames = frames.transpose(0, 3, 1, 2)  # [T, C, H, W]
    
    # åŠ è½½è½¨è¿¹æ•°æ®
    with h5py.File(traj_path, 'r') as f:
        cartesian_positions = f['observation/robot_state/cartesian_position'][:]
        gripper_positions = f['observation/robot_state/gripper_position'][:]
    
    # åˆå¹¶çŠ¶æ€ [x, y, z, rx, ry, rz, gripper]
    states = np.concatenate([cartesian_positions, gripper_positions[:, None]], axis=1)
    
    return frames, states

print("ğŸ“¥ åŠ è½½æµ‹è¯•è½¨è¿¹æ•°æ®...")
np_clips, np_states = load_navigation_episode(test_episode_path)

# æ£€æŸ¥æ•°æ®ç»´åº¦
print(f"ğŸ“Š è§†é¢‘ç»´åº¦: {np_clips.shape}")  # [T, C, H, W]
print(f"ğŸ“Š çŠ¶æ€ç»´åº¦: {np_states.shape}")  # [T, 7]
print(f"ğŸ“Š è½¨è¿¹é•¿åº¦: {len(np_states)} æ­¥")

# æ˜¾ç¤ºä½ç½®å’Œè§’åº¦èŒƒå›´
pos_range_x = (np_states[:, 0].min(), np_states[:, 0].max())
pos_range_y = (np_states[:, 1].min(), np_states[:, 1].max())
yaw_range = (np_states[:, 5].min(), np_states[:, 5].max())

print(f"ğŸ“ Xä½ç½®èŒƒå›´: {pos_range_x[0]:.2f} ~ {pos_range_x[1]:.2f} m")
print(f"ğŸ“ Yä½ç½®èŒƒå›´: {pos_range_y[0]:.2f} ~ {pos_range_y[1]:.2f} m") 
print(f"ğŸ§­ Yawè§’åº¦èŒƒå›´: {yaw_range[0]:.2f} ~ {yaw_range[1]:.2f} rad ({np.degrees(yaw_range[0]):.1f}Â° ~ {np.degrees(yaw_range[1]):.1f}Â°)")

# è½¬æ¢ä¸ºtorch tensors
# np_clips shape: [T, C, H, W] -> need [T, H, W, C] for transform
np_clips_for_transform = np_clips.transpose(0, 2, 3, 1)  # [T, C, H, W] -> [T, H, W, C]
clips = transform(np_clips_for_transform).unsqueeze(0).to(device)  # [1, C, T, H, W]
states = torch.tensor(np_states, dtype=torch.float32, device=device)

print("âœ… æµ‹è¯•æ•°æ®åŠ è½½å®Œæˆ")

#%%
"""
Cell 5: å¯è§†åŒ–åŸå§‹è½¨è¿¹æ•°æ®
"""

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# å·¦å›¾ï¼š2Dè½¨è¿¹
ax1.plot(np_states[:, 0], np_states[:, 1], 'b-', linewidth=2, alpha=0.8, label='Navigation Path')
ax1.plot(np_states[0, 0], np_states[0, 1], 'go', markersize=10, label='Start', zorder=5)
ax1.plot(np_states[-1, 0], np_states[-1, 1], 'ro', markersize=10, label='Goal', zorder=5)

# æ·»åŠ æ–¹å‘ç®­å¤´
arrow_interval = max(1, len(np_states) // 10)
for i in range(0, len(np_states), arrow_interval):
    dx = 0.3 * np.cos(np_states[i, 5])
    dy = 0.3 * np.sin(np_states[i, 5])
    ax1.arrow(np_states[i, 0], np_states[i, 1], dx, dy, 
             head_width=0.1, head_length=0.05, fc='blue', alpha=0.6)

ax1.set_xlabel('X (meters)')
ax1.set_ylabel('Y (meters)')
ax1.set_title('Original Navigation Trajectory')
ax1.legend()
ax1.grid(True, alpha=0.3)
ax1.axis('equal')

# å³å›¾ï¼šè§†é¢‘å¸§æ‹¼æ¥æ˜¾ç¤º
T = min(10, len(np_clips))  # æ˜¾ç¤ºå‰10å¸§
frame_mosaic = np.concatenate([np_clips[i].transpose(1, 2, 0) for i in range(T)], axis=1)
ax2.imshow(frame_mosaic)
ax2.set_title(f'First {T} Video Frames')
ax2.axis('off')

plt.tight_layout()
plt.show()

print("âœ… åŸå§‹æ•°æ®å¯è§†åŒ–å®Œæˆ")

#%%
"""
Cell 6: è®¾ç½®æµ‹è¯•åœºæ™¯å‚æ•°
"""

# æµ‹è¯•åœºæ™¯è®¾ç½®
trajectory_length = len(states)
start_idx = max(0, trajectory_length // 2 - 2)  # ä»ä¸­é—´åå‰å¼€å§‹
prediction_horizon = 3                           # é¢„æµ‹3æ­¥ï¼ˆæ›´ç°å®çš„çŸ­æœŸé¢„æµ‹ï¼‰
goal_idx = min(start_idx + prediction_horizon, trajectory_length - 1)  # ç›®æ ‡æ˜¯3æ­¥å
context_length = 2                               # ä½¿ç”¨2å¸§ä½œä¸ºä¸Šä¸‹æ–‡

print(f"ğŸ¯ æµ‹è¯•åœºæ™¯è®¾ç½®:")
print(f"   è½¨è¿¹æ€»é•¿åº¦: {trajectory_length} æ­¥")
print(f"   èµ·å§‹ä½ç½®: ç¬¬ {start_idx} æ­¥")  
print(f"   ç›®æ ‡ä½ç½®: ç¬¬ {goal_idx} æ­¥")
print(f"   é¢„æµ‹é•¿åº¦: {goal_idx - start_idx} æ­¥ (çŸ­æœŸé¢„æµ‹)")
print(f"   ä¸Šä¸‹æ–‡é•¿åº¦: {context_length} å¸§")

# æå–æµ‹è¯•ç‰‡æ®µ
test_clips = clips[:, :, start_idx:start_idx+context_length]  # [1, C, context_length, H, W]
test_states = states[start_idx:start_idx+context_length]      # [context_length, 7]
goal_clips = clips[:, :, goal_idx:goal_idx+1]                # [1, C, 1, H, W]
goal_states = states[goal_idx:goal_idx+1]                     # [1, 7]

# æ˜¾ç¤ºå½“å‰ä½ç½®å’Œç›®æ ‡ä½ç½®
current_pos = test_states[-1, [0, 1]].cpu().numpy()
goal_pos = goal_states[0, [0, 1]].cpu().numpy()
distance_to_goal = np.linalg.norm(goal_pos - current_pos)

print(f"ğŸ“ å½“å‰ä½ç½®: ({current_pos[0]:.2f}, {current_pos[1]:.2f})")
print(f"ğŸ“ ç›®æ ‡ä½ç½®: ({goal_pos[0]:.2f}, {goal_pos[1]:.2f})")
print(f"ğŸ“ ç›´çº¿è·ç¦»: {distance_to_goal:.2f} m")

print("âœ… æµ‹è¯•åœºæ™¯å‚æ•°è®¾ç½®å®Œæˆ")

#%%
"""
Cell 7: è®¾ç½®å¯¼èˆªä¸“ç”¨çš„ä¸–ç•Œæ¨¡å‹
"""

def make_navigation_action_grid(grid_size_xy=0.1, grid_size_yaw=0.2, nsamples=3, device='cpu'):
    """
    å¯¼èˆªä¸“ç”¨åŠ¨ä½œé‡‡æ ·ï¼šåªåœ¨ [x, y, yaw] ç»´åº¦é‡‡æ ·
    è¿”å› nsamples^3 ä¸ªåŠ¨ä½œæ ·æœ¬
    """
    action_samples = []
    for dx in np.linspace(-grid_size_xy, grid_size_xy, nsamples):
        for dy in np.linspace(-grid_size_xy, grid_size_xy, nsamples):
            for dyaw in np.linspace(-grid_size_yaw, grid_size_yaw, nsamples):
                # æ„é€ 7DOFåŠ¨ä½œï¼š[x, y, z=0, rx=0, ry=0, rz=yaw, gripper=0]
                action = torch.tensor([dx, dy, 0.0, 0.0, 0.0, dyaw, 0.0], 
                                    device=device, dtype=torch.float32)
                action_samples.append(action)
    return torch.stack(action_samples, dim=0).unsqueeze(1)  # [N, 1, 7]

# å¯¼èˆªä¸“ç”¨çš„ä¸–ç•Œæ¨¡å‹é…ç½®
navigation_mpc_args = {
    "rollout": 2,                # é¢„æµ‹æ­¥æ•°
    "samples": 27,               # 3^3 = 27ä¸ªåŠ¨ä½œæ ·æœ¬
    "topk": 9,                   # é€‰æ‹©top-9
    "cem_steps": 3,              # CEMè¿­ä»£æ¬¡æ•°
    "momentum_mean": 0.2,        # å‡å€¼åŠ¨é‡
    "momentum_std": 0.6,         # æ ‡å‡†å·®åŠ¨é‡  
    "maxnorm": 0.15,            # æœ€å¤§åŠ¨ä½œå¹…åº¦
    "verbose": True              # è¾“å‡ºè¯¦ç»†ä¿¡æ¯
}

print(f"ğŸ¤– ä¸–ç•Œæ¨¡å‹é…ç½®:")
for key, value in navigation_mpc_args.items():
    print(f"   {key}: {value}")

# åˆ›å»ºä¸–ç•Œæ¨¡å‹åŒ…è£…å™¨
world_model = WorldModel(
    encoder=encoder,
    predictor=predictor,
    tokens_per_frame=tokens_per_frame,
    transform=lambda x: x,  # æ•°æ®å·²ç»é¢„å¤„ç†è¿‡äº†
    mpc_args=navigation_mpc_args,
    normalize_reps=True,
    device=device
)

print("âœ… å¯¼èˆªä¸–ç•Œæ¨¡å‹åˆå§‹åŒ–å®Œæˆ")

#%%
"""  
Cell 8: è¿è¡Œä¸–ç•Œæ¨¡å‹é¢„æµ‹
"""

print("ğŸš€ å¼€å§‹ä¸–ç•Œæ¨¡å‹é¢„æµ‹...")

# å‰å‘ä¼ æ’­è·å–è¡¨ç¤º
def forward_target(clips_batch, normalize_reps=True):
    """è·å–è§†é¢‘å¸§çš„ç¼–ç è¡¨ç¤º"""
    B, C, T, H, W = clips_batch.size()
    clips_reshaped = clips_batch.permute(0, 2, 1, 3, 4).flatten(0, 1).unsqueeze(2).repeat(1, 1, 2, 1, 1)
    
    with torch.no_grad():
        h = encoder(clips_reshaped)
        h = h.view(B, T, -1, h.size(-1)).flatten(1, 2)
        if normalize_reps:
            h = torch.nn.functional.layer_norm(h, (h.size(-1),))
    return h

# è·å–ä¸Šä¸‹æ–‡å’Œç›®æ ‡çš„è¡¨ç¤º
print("ğŸ”® ç¼–ç ä¸Šä¸‹æ–‡å¸§...")
context_rep = forward_target(test_clips)  # [1, context_length * tokens_per_frame, D]

print("ğŸ¯ ç¼–ç ç›®æ ‡å¸§...")  
goal_rep = forward_target(goal_clips)     # [1, tokens_per_frame, D]

print("ğŸ§  è¿è¡ŒCEMä¼˜åŒ–...")
with torch.no_grad():
    # æå–ä¸Šä¸‹æ–‡è¡¨ç¤ºå’ŒçŠ¶æ€
    z_context = context_rep[:, :tokens_per_frame]  # æœ€æ–°å¸§çš„è¡¨ç¤º
    z_goal = goal_rep[:, -tokens_per_frame:]       # ç›®æ ‡å¸§çš„è¡¨ç¤º
    s_context = test_states[-1:].unsqueeze(0)     # [1, 1, 7] å½“å‰çŠ¶æ€
    
    # ä½¿ç”¨ä¸–ç•Œæ¨¡å‹è§„åˆ’ä¸‹ä¸€æ­¥åŠ¨ä½œ
    planned_actions = world_model.infer_next_action(z_context, s_context, z_goal)
    
print(f"âœ… è§„åˆ’å®Œæˆï¼")
print(f"ğŸ® è§„åˆ’çš„åŠ¨ä½œ: {planned_actions[0].cpu().numpy()}")

# å°†åŠ¨ä½œåˆ†è§£æ˜¾ç¤º
action_np = planned_actions[0].cpu().numpy()
print(f"   ä½ç§» (x, y): ({action_np[0]:.3f}, {action_np[1]:.3f}) m")
print(f"   æ—‹è½¬ (yaw): {action_np[5]:.3f} rad ({np.degrees(action_np[5]):.1f}Â°)")

#%%
"""
Cell 9: æ¨¡æ‹Ÿæ‰§è¡Œé¢„æµ‹åŠ¨ä½œå¹¶å¯è§†åŒ–
"""

def simulate_action_execution(current_state, action):
    """æ¨¡æ‹Ÿæ‰§è¡Œä¸€ä¸ªåŠ¨ä½œï¼Œè¿”å›æ–°çŠ¶æ€"""
    new_state = current_state.clone()
    new_state[0] += action[0]  # x
    new_state[1] += action[1]  # y  
    new_state[5] += action[5]  # yaw
    return new_state

# ä»å½“å‰ä½ç½®å¼€å§‹ï¼Œæ‰§è¡Œå¤šæ­¥é¢„æµ‹
print("ğŸ”„ æ¨¡æ‹Ÿå¤šæ­¥é¢„æµ‹æ‰§è¡Œ...")

predicted_states = [test_states[-1]]  # èµ·å§‹çŠ¶æ€
current_state = test_states[-1].clone()

# ç®€å•ç­–ç•¥ï¼šé‡å¤æ‰§è¡Œç›¸åŒçš„åŠ¨ä½œï¼ˆå®é™…åº”è¯¥æ¯æ­¥é‡æ–°è§„åˆ’ï¼‰
n_prediction_steps = goal_idx - start_idx  # é¢„æµ‹åˆ°ç›®æ ‡ä½ç½®

for step in range(n_prediction_steps):
    print(f"   æ­¥éª¤ {step+1}/{n_prediction_steps}")
    
    # æ‰§è¡ŒåŠ¨ä½œ
    new_state = simulate_action_execution(current_state, planned_actions[0])
    predicted_states.append(new_state)
    current_state = new_state

# è½¬æ¢ä¸ºnumpyè¿›è¡Œå¯è§†åŒ–
predicted_states_np = torch.stack(predicted_states).cpu().numpy()

# çœŸå®è½¨è¿¹å¯¹æ¯”æ•°æ®
true_states_segment = states[start_idx:start_idx+len(predicted_states)].cpu().numpy()

print("âœ… é¢„æµ‹æ‰§è¡Œå®Œæˆ")

#%%
"""
Cell 10: ç»“æœå¯è§†åŒ–å’Œè¯„ä¼°
"""

def normalize_angle(angle):
    """å°†è§’åº¦è§„èŒƒåŒ–åˆ°[-pi, pi]"""
    while angle > np.pi:
        angle -= 2 * np.pi
    while angle < -np.pi:
        angle += 2 * np.pi
    return angle

def compute_angle_diff(angle1, angle2):
    """è®¡ç®—è§’åº¦å·®"""
    diff = angle2 - angle1
    return normalize_angle(diff)

# è®¡ç®—è¯„ä¼°æŒ‡æ ‡
position_errors = []
angle_errors = []

for i in range(len(true_states_segment)):
    # ä½ç½®è¯¯å·®
    pos_error = np.linalg.norm(
        true_states_segment[i, [0, 1]] - predicted_states_np[i, [0, 1]]
    )
    position_errors.append(pos_error)
    
    # è§’åº¦è¯¯å·®
    angle_error = abs(compute_angle_diff(
        true_states_segment[i, 5], predicted_states_np[i, 5]
    ))
    angle_errors.append(angle_error)

# å¯è§†åŒ–ç»“æœ
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))

# ç¬¬1å­å›¾ï¼š2Dè½¨è¿¹å¯¹æ¯”
ax1.plot(true_states_segment[:, 0], true_states_segment[:, 1], 
         'b-', linewidth=3, label='True Path', alpha=0.8)
ax1.plot(predicted_states_np[:, 0], predicted_states_np[:, 1], 
         'r--', linewidth=3, label='Predicted Path', alpha=0.8)

# æ ‡è®°èµ·ç‚¹å’Œç»ˆç‚¹
ax1.plot(true_states_segment[0, 0], true_states_segment[0, 1], 
         'go', markersize=12, label='Start', zorder=5)
ax1.plot(goal_pos[0], goal_pos[1], 
         'mo', markersize=12, label='Target Goal', zorder=5)

# æ·»åŠ æ–¹å‘ç®­å¤´
for i in range(0, len(true_states_segment), max(1, len(true_states_segment)//3)):
    # çœŸå®æ–¹å‘
    dx = 0.2 * np.cos(true_states_segment[i, 5])
    dy = 0.2 * np.sin(true_states_segment[i, 5])
    ax1.arrow(true_states_segment[i, 0], true_states_segment[i, 1], dx, dy,
             head_width=0.05, head_length=0.03, fc='blue', alpha=0.7)
    
    # é¢„æµ‹æ–¹å‘
    dx = 0.2 * np.cos(predicted_states_np[i, 5])
    dy = 0.2 * np.sin(predicted_states_np[i, 5])
    ax1.arrow(predicted_states_np[i, 0], predicted_states_np[i, 1], dx, dy,
             head_width=0.05, head_length=0.03, fc='red', alpha=0.7)

ax1.set_xlabel('X (meters)')
ax1.set_ylabel('Y (meters)')
ax1.set_title('Navigation World Model Prediction Results')
ax1.legend()
ax1.grid(True, alpha=0.3)
ax1.axis('equal')

# ç¬¬2å­å›¾ï¼šä½ç½®è¯¯å·®
ax2.plot(range(len(position_errors)), position_errors, 'g-o', linewidth=2, markersize=6)
ax2.axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Success Threshold (0.5m)')
ax2.set_xlabel('Time Step')
ax2.set_ylabel('Position Error (m)')
ax2.set_title('Position Error Over Time')
ax2.legend()
ax2.grid(True, alpha=0.3)

# ç¬¬3å­å›¾ï¼šè§’åº¦è¯¯å·®
ax3.plot(range(len(angle_errors)), np.degrees(angle_errors), 'orange', linewidth=2, marker='s', markersize=6)
ax3.axhline(y=np.degrees(0.2), color='red', linestyle='--', alpha=0.7, label='Success Threshold (11.5Â°)')
ax3.set_xlabel('Time Step')
ax3.set_ylabel('Angle Error (degrees)')
ax3.set_title('Angle Error Over Time') 
ax3.legend()
ax3.grid(True, alpha=0.3)

# ç¬¬4å­å›¾ï¼šç»Ÿè®¡æ‘˜è¦
stats_text = f"""Prediction Results Summary:

ğŸ“Š Trajectory Info:
   - Prediction steps: {len(predicted_states_np)}
   - Distance to goal: {distance_to_goal:.2f} m

ğŸ“ Position Metrics:
   - Mean error: {np.mean(position_errors):.3f} m
   - Final error: {position_errors[-1]:.3f} m  
   - Max error: {np.max(position_errors):.3f} m
   - Success rate: {np.mean(np.array(position_errors) < 0.5):.1%}

ğŸ§­ Angle Metrics:
   - Mean error: {np.degrees(np.mean(angle_errors)):.1f}Â°
   - Final error: {np.degrees(angle_errors[-1]):.1f}Â°
   - Max error: {np.degrees(np.max(angle_errors)):.1f}Â°
   - Success rate: {np.mean(np.array(angle_errors) < 0.2):.1%}

ğŸ¯ Overall Performance:
   - Combined success: {np.mean((np.array(position_errors) < 0.5) & (np.array(angle_errors) < 0.2)):.1%}
"""

ax4.text(0.05, 0.95, stats_text, transform=ax4.transAxes, 
         verticalalignment='top', fontfamily='monospace', fontsize=10,
         bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
ax4.axis('off')

plt.tight_layout()
plt.savefig('navigation_worldmodel_results.png', dpi=300, bbox_inches='tight')
plt.show()

print("âœ… ç»“æœå¯è§†åŒ–å®Œæˆ")
print("ğŸ’¾ ç»“æœå·²ä¿å­˜ä¸º 'navigation_worldmodel_results.png'")

#%%
"""
Cell 11: æ€»ç»“å’Œç»“è®º
"""

print("\n" + "="*60)
print("ğŸ å¯¼èˆªä¸–ç•Œæ¨¡å‹æµ‹è¯•æ€»ç»“")
print("="*60)

print(f"\nğŸ“ æµ‹è¯•é…ç½®:")
print(f"   æ¨¡å‹checkpoint: {os.path.basename(checkpoint_path)}")  
print(f"   æµ‹è¯•è½¨è¿¹: {os.path.basename(test_episode_path)}")
print(f"   é¢„æµ‹æ­¥æ•°: {len(predicted_states_np)}")
print(f"   éšæœºç§å­: {RANDOM_SEED}")

print(f"\nğŸ“Š æ€§èƒ½æŒ‡æ ‡:")
print(f"   å¹³å‡ä½ç½®è¯¯å·®: {np.mean(position_errors):.3f} m")
print(f"   å¹³å‡è§’åº¦è¯¯å·®: {np.degrees(np.mean(angle_errors)):.1f}Â°")
print(f"   ä½ç½®æˆåŠŸç‡: {np.mean(np.array(position_errors) < 0.5):.1%} (< 0.5m)")
print(f"   è§’åº¦æˆåŠŸç‡: {np.mean(np.array(angle_errors) < 0.2):.1%} (< 11.5Â°)")

print(f"\nğŸ¯ å…³é”®å‘ç°:")
final_pos_error = position_errors[-1]
final_angle_error = angle_errors[-1]

if final_pos_error < 0.5:
    print("   âœ… æœ€ç»ˆä½ç½®è¯¯å·®åœ¨å¯æ¥å—èŒƒå›´å†…")
else:
    print("   âŒ æœ€ç»ˆä½ç½®è¯¯å·®è¾ƒå¤§ï¼Œéœ€è¦æ”¹è¿›")

if final_angle_error < 0.2:
    print("   âœ… æœ€ç»ˆè§’åº¦è¯¯å·®åœ¨å¯æ¥å—èŒƒå›´å†…")
else:
    print("   âŒ æœ€ç»ˆè§’åº¦è¯¯å·®è¾ƒå¤§ï¼Œéœ€è¦æ”¹è¿›")

print(f"\nğŸ’¡ å»ºè®®:")
if np.mean(position_errors) > 0.3:
    print("   - è€ƒè™‘å¢åŠ CEMé‡‡æ ·æ•°é‡æˆ–è¿­ä»£æ¬¡æ•°")
    print("   - è°ƒæ•´åŠ¨ä½œé‡‡æ ·èŒƒå›´")
if np.mean(angle_errors) > 0.15:
    print("   - è§’åº¦é¢„æµ‹å¯èƒ½éœ€è¦æ›´ç²¾ç»†çš„é‡‡æ ·")
    print("   - æ£€æŸ¥è®­ç»ƒæ•°æ®ä¸­çš„è§’åº¦åˆ†å¸ƒ")

print("="*60)
print("ğŸ‰ æµ‹è¯•å®Œæˆï¼")

# %%
