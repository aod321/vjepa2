#%%
import sys
sys.path.insert(0, "..")

#%%
import numpy as np
import matplotlib.pyplot as plt

import torch
from torch.nn import functional as F

from app.vjepa_droid.transforms import make_transforms
from notebooks.utils.mpc_utils import (
    compute_new_pose,
    poses_to_diff
)

#%%
# Initialize VJEPA 2-AC model
encoder, predictor = torch.hub.load("facebookresearch/vjepa2", "vjepa2_ac_vit_giant")

# 移动模型到GPU
device = "cuda:7"
encoder = encoder.to(device)
predictor = predictor.to(device)
print(f"Models moved to {device}")
print(f"Encoder device: {next(encoder.parameters()).device}")
print(f"Predictor device: {next(predictor.parameters()).device}")

# Initialize transform
crop_size = 256
tokens_per_frame = int((crop_size // encoder.patch_size) ** 2)
transform = make_transforms(
    random_horizontal_flip=False,
    random_resize_aspect_ratio=(1., 1.),
    random_resize_scale=(1., 1.),
    reprob=0.,
    auto_augment=False,
    motion_shift=False,
    crop_size=crop_size,
)

#%%
# Load robot trajectory

play_in_reverse = False  # Use this FLAG to try loading the trajectory backwards, and see how the energy landscape changes

trajectory = np.load("notebooks/franka_example_traj.npz")
np_clips = trajectory["observations"]
np_states = trajectory["states"]
if play_in_reverse:
    np_clips = trajectory["observations"][:, ::-1].copy()
    np_states = trajectory["states"][:, ::-1].copy()
np_actions = np.expand_dims(poses_to_diff(np_states[0, 0], np_states[0, 1]), axis=(0, 1))

#%%
# Convert trajectory to torch tensors
clips = transform(np_clips[0]).unsqueeze(0).to(device)
states = torch.tensor(np_states).to(device)
actions = torch.tensor(np_actions).to(device)
print(f"clips: {clips.shape}; states: {states.shape}; actions: {actions.shape}")
print(f"clips device: {clips.device}")
print(f"states device: {states.device}")

#%%
# Visualize loaded video frames from traj

T = len(np_clips[0])
plt.figure(figsize=(20, 3))
_ = plt.imshow(np.transpose(np_clips[0], (1, 0, 2, 3)).reshape(256, 256 * T, 3))
#%%
#%%
import matplotlib.pyplot as plt

# 假设 np_states 形状为 [batch, time, 7]
a_states = np_states[0]  # 取第一条轨迹

# 3D位置轨迹
fig = plt.figure(figsize=(10, 4))

# 位置 xyz
plt.subplot(1, 2, 1)
plt.plot(a_states[:, 0], label='x')
plt.plot(a_states[:, 1], label='y')
plt.plot(a_states[:, 2], label='z')
plt.legend()
plt.title('Position')

# 欧拉角 + 夹爪
plt.subplot(1, 2, 2)
plt.plot(a_states[:, 3], label='rx')
plt.plot(a_states[:, 4], label='ry')
plt.plot(a_states[:, 5], label='rz')
plt.plot(a_states[:, 6], label='gripper')
plt.legend()
plt.title('Rotation + Gripper')
plt.show()
#%%
def forward_target(c, normalize_reps=True):
    B, C, T, H, W = c.size()
    c = c.permute(0, 2, 1, 3, 4).flatten(0, 1).unsqueeze(2).repeat(1, 1, 2, 1, 1)
    h = encoder(c)
    h = h.view(B, T, -1, h.size(-1)).flatten(1, 2)
    if normalize_reps:
        h = F.layer_norm(h, (h.size(-1),))
    return h


def forward_actions(z, nsamples, grid_size=0.075, normalize_reps=True, action_repeat=1):

    def make_action_grid(grid_size=grid_size):
        action_samples = []
        for da in np.linspace(-grid_size, grid_size, nsamples):
            for db in np.linspace(-grid_size, grid_size, nsamples):
                for dc in np.linspace(-grid_size, grid_size, nsamples):
                    action_samples += [torch.tensor([da, db, dc, 0, 0, 0, 0], device=z.device, dtype=z.dtype)]
        return torch.stack(action_samples, dim=0).unsqueeze(1)

    # Sample grid of actions
    action_samples = make_action_grid()
    print(f"Sampled grid of actions; num actions = {len(action_samples)}")

    def step_predictor(_z, _a, _s):
        _z = predictor(_z, _a, _s)[:, -tokens_per_frame:]
        if normalize_reps:
            _z = F.layer_norm(_z, (_z.size(-1),))
        _s = compute_new_pose(_s[:, -1:], _a[:, -1:])
        return _z, _s

    # Context frame rep and context pose
    z_hat = z[:, :tokens_per_frame].repeat(int(nsamples**3), 1, 1)  # [S, N, D]
    s_hat = states[:, :1].repeat((int(nsamples**3), 1, 1))  # [S, 1, 7]
    a_hat = action_samples  # [S, 1, 7]

    for _ in range(action_repeat):
        _z, _s = step_predictor(z_hat, a_hat, s_hat)
        z_hat = torch.cat([z_hat, _z], dim=1)
        s_hat = torch.cat([s_hat, _s], dim=1)
        a_hat = torch.cat([a_hat, action_samples], dim=1)

    return z_hat, s_hat, a_hat

def loss_fn(z, h):
    z, h = z[:, -tokens_per_frame:], h[:, -tokens_per_frame:]
    loss = torch.abs(z - h)  # [B, N, D]
    loss = torch.mean(loss, dim=[1, 2])
    return loss.tolist()

#%%
# Compute the optimal action using MPC
from notebooks.utils.world_model_wrapper import WorldModel

world_model = WorldModel(
    encoder=encoder,
    predictor=predictor,
    tokens_per_frame=tokens_per_frame,
    transform=transform,
    # Doing very few CEM iterations with very few samples just to run efficiently on CPU...
    # ... increase cem_steps and samples for more accurate optimization of energy landscape
    mpc_args={
        "rollout": 2,
        "samples": 100,
        "topk": 30,
        "cem_steps": 500,
        "momentum_mean": 0.15,
        "momentum_mean_gripper": 0.15,
        "momentum_std": 0.75,
        "momentum_std_gripper": 0.15,
        "maxnorm": 0.075,
        "verbose": True
    },
    normalize_reps=True,
    force_gpu=True,
    device="cuda:7"
)

with torch.no_grad():
    h = forward_target(clips)
    z_n, z_goal = h[:, :tokens_per_frame], h[:, -tokens_per_frame:]
    s_n = states[:, :1]
    print(f"Starting planning using Cross-Entropy Method...")
    actions = world_model.infer_next_action(z_n, s_n, z_goal, show_progress=True).cpu().numpy()

print(f"Actions returned by planning with CEM (x,y,z) = ({actions[0, 0]:.2f},{actions[0, 1]:.2f} {actions[0, 2]:.2f})")
# %%        
# 比较 CEM 优化的动作与 GT
# cem_action = actions[0, 0, :]  # CEM结果
cem_action = actions[0]  # 形状: [7]
gt_action = poses_to_diff(np_states[0, 0], np_states[0, 1])

# 转换为相同类型
if isinstance(gt_action, torch.Tensor):
    gt_action = gt_action.cpu().numpy()
if isinstance(cem_action, torch.Tensor):
    cem_action = cem_action.cpu().numpy()

# 计算误差
error = np.linalg.norm(cem_action - gt_action)
print(f"CEM action: {cem_action}")
print(f"GT action: {gt_action}")
print(f"L2 error: {error:.4f}")
# %%
